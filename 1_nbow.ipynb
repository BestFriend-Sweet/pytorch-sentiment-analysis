{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e322bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import datasets\n",
    "\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc98ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f31d8064b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798f5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = datasets.load_dataset('imdb', split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42338609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['label', 'text'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['label', 'text'],\n",
       "     num_rows: 25000\n",
       " }))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a6e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3017c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876ad3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(example, tokenizer, max_length):\n",
    "    tokens = {'tokens': tokenizer(example['text'])}\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e295030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-7842cabd40e75acb.arrow\n",
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-bfe5116f071dbe09.arrow\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "train_data = train_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})\n",
    "test_data = test_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f647bdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'tokens'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f3de3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': 'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!',\n",
       " 'tokens': ['bromwell',\n",
       "  'high',\n",
       "  'is',\n",
       "  'a',\n",
       "  'cartoon',\n",
       "  'comedy',\n",
       "  '.',\n",
       "  'it',\n",
       "  'ran',\n",
       "  'at',\n",
       "  'the',\n",
       "  'same',\n",
       "  'time',\n",
       "  'as',\n",
       "  'some',\n",
       "  'other',\n",
       "  'programs',\n",
       "  'about',\n",
       "  'school',\n",
       "  'life',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'teachers',\n",
       "  '.',\n",
       "  'my',\n",
       "  '35',\n",
       "  'years',\n",
       "  'in',\n",
       "  'the',\n",
       "  'teaching',\n",
       "  'profession',\n",
       "  'lead',\n",
       "  'me',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'satire',\n",
       "  'is',\n",
       "  'much',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'reality',\n",
       "  'than',\n",
       "  'is',\n",
       "  'teachers',\n",
       "  '.',\n",
       "  'the',\n",
       "  'scramble',\n",
       "  'to',\n",
       "  'survive',\n",
       "  'financially',\n",
       "  ',',\n",
       "  'the',\n",
       "  'insightful',\n",
       "  'students',\n",
       "  'who',\n",
       "  'can',\n",
       "  'see',\n",
       "  'right',\n",
       "  'through',\n",
       "  'their',\n",
       "  'pathetic',\n",
       "  'teachers',\n",
       "  \"'\",\n",
       "  'pomp',\n",
       "  ',',\n",
       "  'the',\n",
       "  'pettiness',\n",
       "  'of',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'situation',\n",
       "  ',',\n",
       "  'all',\n",
       "  'remind',\n",
       "  'me',\n",
       "  'of',\n",
       "  'the',\n",
       "  'schools',\n",
       "  'i',\n",
       "  'knew',\n",
       "  'and',\n",
       "  'their',\n",
       "  'students',\n",
       "  '.',\n",
       "  'when',\n",
       "  'i',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'episode',\n",
       "  'in',\n",
       "  'which',\n",
       "  'a',\n",
       "  'student',\n",
       "  'repeatedly',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'burn',\n",
       "  'down',\n",
       "  'the',\n",
       "  'school',\n",
       "  ',',\n",
       "  'i',\n",
       "  'immediately',\n",
       "  'recalled',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'at',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'high',\n",
       "  '.',\n",
       "  'a',\n",
       "  'classic',\n",
       "  'line',\n",
       "  'inspector',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'here',\n",
       "  'to',\n",
       "  'sack',\n",
       "  'one',\n",
       "  'of',\n",
       "  'your',\n",
       "  'teachers',\n",
       "  '.',\n",
       "  'student',\n",
       "  'welcome',\n",
       "  'to',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  '.',\n",
       "  'i',\n",
       "  'expect',\n",
       "  'that',\n",
       "  'many',\n",
       "  'adults',\n",
       "  'of',\n",
       "  'my',\n",
       "  'age',\n",
       "  'think',\n",
       "  'that',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'is',\n",
       "  'far',\n",
       "  'fetched',\n",
       "  '.',\n",
       "  'what',\n",
       "  'a',\n",
       "  'pity',\n",
       "  'that',\n",
       "  'it',\n",
       "  'isn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  '!']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e48bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-8accbbb83db0be7f.arrow and /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-5ccc1cf561f81a9c.arrow\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "\n",
    "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
    "train_data = train_valid_data['train']\n",
    "valid_data = train_valid_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881e83b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': \"Made in 1946 and released in 1948, The Lady and Shanghai was one of the big films made by Welles after returning from relative exile for making Citizen Kane. Dark, brooding and expressing some early Cold War paranoia, this film stands tall as a Film-Noir crime film. The cinematography of this film is filled with Welles' characteristic quirks of odd angles, quick cuts, long pans and sinister lighting. The use of ambient street music is a precursor to the incredible long opening shot in Touch of Evil, and the mysterious Chinese characters and the sequences in Chinatown can only be considered as the inspiration, in many ways, to Roman Polanski's Chinatown. Unfortunately, it is Welles' obsession with technical filmmaking that hurts this film in its entirety. The plot of this story is often lost behind a sometimes incomprehensible clutter of film techniques.<br /><br />However, despite this criticism, the story combined with wonderful performances by Welles, Hayworth and especially Glenn Anders (Laughter) make this film a joy to watch. Orson Welles pulls off not only the Irish brogue, but the torn identities as the honest but dangerous sailor. Rita Hayworth, who was married to Welles at the time, breaks with her usual roles as a sex goddess and takes on a role of real depth and contradictions. Finally, Glenn Anders strange and bizarre portrayal or Elsa's husbands' law partner is nothing short of classic!\",\n",
       " 'tokens': ['made',\n",
       "  'in',\n",
       "  '1946',\n",
       "  'and',\n",
       "  'released',\n",
       "  'in',\n",
       "  '1948',\n",
       "  ',',\n",
       "  'the',\n",
       "  'lady',\n",
       "  'and',\n",
       "  'shanghai',\n",
       "  'was',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'big',\n",
       "  'films',\n",
       "  'made',\n",
       "  'by',\n",
       "  'welles',\n",
       "  'after',\n",
       "  'returning',\n",
       "  'from',\n",
       "  'relative',\n",
       "  'exile',\n",
       "  'for',\n",
       "  'making',\n",
       "  'citizen',\n",
       "  'kane',\n",
       "  '.',\n",
       "  'dark',\n",
       "  ',',\n",
       "  'brooding',\n",
       "  'and',\n",
       "  'expressing',\n",
       "  'some',\n",
       "  'early',\n",
       "  'cold',\n",
       "  'war',\n",
       "  'paranoia',\n",
       "  ',',\n",
       "  'this',\n",
       "  'film',\n",
       "  'stands',\n",
       "  'tall',\n",
       "  'as',\n",
       "  'a',\n",
       "  'film-noir',\n",
       "  'crime',\n",
       "  'film',\n",
       "  '.',\n",
       "  'the',\n",
       "  'cinematography',\n",
       "  'of',\n",
       "  'this',\n",
       "  'film',\n",
       "  'is',\n",
       "  'filled',\n",
       "  'with',\n",
       "  'welles',\n",
       "  \"'\",\n",
       "  'characteristic',\n",
       "  'quirks',\n",
       "  'of',\n",
       "  'odd',\n",
       "  'angles',\n",
       "  ',',\n",
       "  'quick',\n",
       "  'cuts',\n",
       "  ',',\n",
       "  'long',\n",
       "  'pans',\n",
       "  'and',\n",
       "  'sinister',\n",
       "  'lighting',\n",
       "  '.',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'ambient',\n",
       "  'street',\n",
       "  'music',\n",
       "  'is',\n",
       "  'a',\n",
       "  'precursor',\n",
       "  'to',\n",
       "  'the',\n",
       "  'incredible',\n",
       "  'long',\n",
       "  'opening',\n",
       "  'shot',\n",
       "  'in',\n",
       "  'touch',\n",
       "  'of',\n",
       "  'evil',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'mysterious',\n",
       "  'chinese',\n",
       "  'characters',\n",
       "  'and',\n",
       "  'the',\n",
       "  'sequences',\n",
       "  'in',\n",
       "  'chinatown',\n",
       "  'can',\n",
       "  'only',\n",
       "  'be',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'inspiration',\n",
       "  ',',\n",
       "  'in',\n",
       "  'many',\n",
       "  'ways',\n",
       "  ',',\n",
       "  'to',\n",
       "  'roman',\n",
       "  'polanski',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'chinatown',\n",
       "  '.',\n",
       "  'unfortunately',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'welles',\n",
       "  \"'\",\n",
       "  'obsession',\n",
       "  'with',\n",
       "  'technical',\n",
       "  'filmmaking',\n",
       "  'that',\n",
       "  'hurts',\n",
       "  'this',\n",
       "  'film',\n",
       "  'in',\n",
       "  'its',\n",
       "  'entirety',\n",
       "  '.',\n",
       "  'the',\n",
       "  'plot',\n",
       "  'of',\n",
       "  'this',\n",
       "  'story',\n",
       "  'is',\n",
       "  'often',\n",
       "  'lost',\n",
       "  'behind',\n",
       "  'a',\n",
       "  'sometimes',\n",
       "  'incomprehensible',\n",
       "  'clutter',\n",
       "  'of',\n",
       "  'film',\n",
       "  'techniques',\n",
       "  '.',\n",
       "  'however',\n",
       "  ',',\n",
       "  'despite',\n",
       "  'this',\n",
       "  'criticism',\n",
       "  ',',\n",
       "  'the',\n",
       "  'story',\n",
       "  'combined',\n",
       "  'with',\n",
       "  'wonderful',\n",
       "  'performances',\n",
       "  'by',\n",
       "  'welles',\n",
       "  ',',\n",
       "  'hayworth',\n",
       "  'and',\n",
       "  'especially',\n",
       "  'glenn',\n",
       "  'anders',\n",
       "  '(',\n",
       "  'laughter',\n",
       "  ')',\n",
       "  'make',\n",
       "  'this',\n",
       "  'film',\n",
       "  'a',\n",
       "  'joy',\n",
       "  'to',\n",
       "  'watch',\n",
       "  '.',\n",
       "  'orson',\n",
       "  'welles',\n",
       "  'pulls',\n",
       "  'off',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'irish',\n",
       "  'brogue',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'torn',\n",
       "  'identities',\n",
       "  'as',\n",
       "  'the',\n",
       "  'honest',\n",
       "  'but',\n",
       "  'dangerous',\n",
       "  'sailor',\n",
       "  '.',\n",
       "  'rita',\n",
       "  'hayworth',\n",
       "  ',',\n",
       "  'who',\n",
       "  'was',\n",
       "  'married',\n",
       "  'to',\n",
       "  'welles',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time',\n",
       "  ',',\n",
       "  'breaks',\n",
       "  'with',\n",
       "  'her',\n",
       "  'usual',\n",
       "  'roles',\n",
       "  'as',\n",
       "  'a',\n",
       "  'sex',\n",
       "  'goddess',\n",
       "  'and',\n",
       "  'takes',\n",
       "  'on',\n",
       "  'a',\n",
       "  'role',\n",
       "  'of',\n",
       "  'real',\n",
       "  'depth',\n",
       "  'and',\n",
       "  'contradictions',\n",
       "  '.',\n",
       "  'finally',\n",
       "  ',',\n",
       "  'glenn',\n",
       "  'anders',\n",
       "  'strange',\n",
       "  'and',\n",
       "  'bizarre',\n",
       "  'portrayal',\n",
       "  'or',\n",
       "  'elsa',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'husbands',\n",
       "  \"'\",\n",
       "  'law',\n",
       "  'partner',\n",
       "  'is',\n",
       "  'nothing',\n",
       "  'short',\n",
       "  'of',\n",
       "  'classic',\n",
       "  '!']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c227e4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18750, 6250, 25000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4865e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 5\n",
    "special_tokens = ['<unk>', '<pad>']\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(train_data['tokens'],\n",
    "                                                  min_freq=min_freq,\n",
    "                                                  specials=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123ceb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26232"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ec89de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ac49c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_index = vocab['<unk>']\n",
    "\n",
    "unk_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "447020e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_index = vocab['<pad>']\n",
    "\n",
    "pad_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "201b5383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'some_token' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a951ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "407fe05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['some_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76518d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_data(example, vocab):\n",
    "    ids = {'ids': [vocab[token] for token in example['tokens']]}\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dacaeaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-0711fb1236178dd5.arrow\n",
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-50be229d07f157d2.arrow\n",
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-e956c9a4a1d5a9aa.arrow\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\n",
    "valid_data = valid_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\n",
    "test_data = test_data.map(numericalize_data, fn_kwargs={'vocab': vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08751c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': \"Made in 1946 and released in 1948, The Lady and Shanghai was one of the big films made by Welles after returning from relative exile for making Citizen Kane. Dark, brooding and expressing some early Cold War paranoia, this film stands tall as a Film-Noir crime film. The cinematography of this film is filled with Welles' characteristic quirks of odd angles, quick cuts, long pans and sinister lighting. The use of ambient street music is a precursor to the incredible long opening shot in Touch of Evil, and the mysterious Chinese characters and the sequences in Chinatown can only be considered as the inspiration, in many ways, to Roman Polanski's Chinatown. Unfortunately, it is Welles' obsession with technical filmmaking that hurts this film in its entirety. The plot of this story is often lost behind a sometimes incomprehensible clutter of film techniques.<br /><br />However, despite this criticism, the story combined with wonderful performances by Welles, Hayworth and especially Glenn Anders (Laughter) make this film a joy to watch. Orson Welles pulls off not only the Irish brogue, but the torn identities as the honest but dangerous sailor. Rita Hayworth, who was married to Welles at the time, breaks with her usual roles as a sex goddess and takes on a role of real depth and contradictions. Finally, Glenn Anders strange and bizarre portrayal or Elsa's husbands' law partner is nothing short of classic!\",\n",
       " 'tokens': ['made',\n",
       "  'in',\n",
       "  '1946',\n",
       "  'and',\n",
       "  'released',\n",
       "  'in',\n",
       "  '1948',\n",
       "  ',',\n",
       "  'the',\n",
       "  'lady',\n",
       "  'and',\n",
       "  'shanghai',\n",
       "  'was',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'big',\n",
       "  'films',\n",
       "  'made',\n",
       "  'by',\n",
       "  'welles',\n",
       "  'after',\n",
       "  'returning',\n",
       "  'from',\n",
       "  'relative',\n",
       "  'exile',\n",
       "  'for',\n",
       "  'making',\n",
       "  'citizen',\n",
       "  'kane',\n",
       "  '.',\n",
       "  'dark',\n",
       "  ',',\n",
       "  'brooding',\n",
       "  'and',\n",
       "  'expressing',\n",
       "  'some',\n",
       "  'early',\n",
       "  'cold',\n",
       "  'war',\n",
       "  'paranoia',\n",
       "  ',',\n",
       "  'this',\n",
       "  'film',\n",
       "  'stands',\n",
       "  'tall',\n",
       "  'as',\n",
       "  'a',\n",
       "  'film-noir',\n",
       "  'crime',\n",
       "  'film',\n",
       "  '.',\n",
       "  'the',\n",
       "  'cinematography',\n",
       "  'of',\n",
       "  'this',\n",
       "  'film',\n",
       "  'is',\n",
       "  'filled',\n",
       "  'with',\n",
       "  'welles',\n",
       "  \"'\",\n",
       "  'characteristic',\n",
       "  'quirks',\n",
       "  'of',\n",
       "  'odd',\n",
       "  'angles',\n",
       "  ',',\n",
       "  'quick',\n",
       "  'cuts',\n",
       "  ',',\n",
       "  'long',\n",
       "  'pans',\n",
       "  'and',\n",
       "  'sinister',\n",
       "  'lighting',\n",
       "  '.',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'ambient',\n",
       "  'street',\n",
       "  'music',\n",
       "  'is',\n",
       "  'a',\n",
       "  'precursor',\n",
       "  'to',\n",
       "  'the',\n",
       "  'incredible',\n",
       "  'long',\n",
       "  'opening',\n",
       "  'shot',\n",
       "  'in',\n",
       "  'touch',\n",
       "  'of',\n",
       "  'evil',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'mysterious',\n",
       "  'chinese',\n",
       "  'characters',\n",
       "  'and',\n",
       "  'the',\n",
       "  'sequences',\n",
       "  'in',\n",
       "  'chinatown',\n",
       "  'can',\n",
       "  'only',\n",
       "  'be',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'inspiration',\n",
       "  ',',\n",
       "  'in',\n",
       "  'many',\n",
       "  'ways',\n",
       "  ',',\n",
       "  'to',\n",
       "  'roman',\n",
       "  'polanski',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'chinatown',\n",
       "  '.',\n",
       "  'unfortunately',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'welles',\n",
       "  \"'\",\n",
       "  'obsession',\n",
       "  'with',\n",
       "  'technical',\n",
       "  'filmmaking',\n",
       "  'that',\n",
       "  'hurts',\n",
       "  'this',\n",
       "  'film',\n",
       "  'in',\n",
       "  'its',\n",
       "  'entirety',\n",
       "  '.',\n",
       "  'the',\n",
       "  'plot',\n",
       "  'of',\n",
       "  'this',\n",
       "  'story',\n",
       "  'is',\n",
       "  'often',\n",
       "  'lost',\n",
       "  'behind',\n",
       "  'a',\n",
       "  'sometimes',\n",
       "  'incomprehensible',\n",
       "  'clutter',\n",
       "  'of',\n",
       "  'film',\n",
       "  'techniques',\n",
       "  '.',\n",
       "  'however',\n",
       "  ',',\n",
       "  'despite',\n",
       "  'this',\n",
       "  'criticism',\n",
       "  ',',\n",
       "  'the',\n",
       "  'story',\n",
       "  'combined',\n",
       "  'with',\n",
       "  'wonderful',\n",
       "  'performances',\n",
       "  'by',\n",
       "  'welles',\n",
       "  ',',\n",
       "  'hayworth',\n",
       "  'and',\n",
       "  'especially',\n",
       "  'glenn',\n",
       "  'anders',\n",
       "  '(',\n",
       "  'laughter',\n",
       "  ')',\n",
       "  'make',\n",
       "  'this',\n",
       "  'film',\n",
       "  'a',\n",
       "  'joy',\n",
       "  'to',\n",
       "  'watch',\n",
       "  '.',\n",
       "  'orson',\n",
       "  'welles',\n",
       "  'pulls',\n",
       "  'off',\n",
       "  'not',\n",
       "  'only',\n",
       "  'the',\n",
       "  'irish',\n",
       "  'brogue',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'torn',\n",
       "  'identities',\n",
       "  'as',\n",
       "  'the',\n",
       "  'honest',\n",
       "  'but',\n",
       "  'dangerous',\n",
       "  'sailor',\n",
       "  '.',\n",
       "  'rita',\n",
       "  'hayworth',\n",
       "  ',',\n",
       "  'who',\n",
       "  'was',\n",
       "  'married',\n",
       "  'to',\n",
       "  'welles',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time',\n",
       "  ',',\n",
       "  'breaks',\n",
       "  'with',\n",
       "  'her',\n",
       "  'usual',\n",
       "  'roles',\n",
       "  'as',\n",
       "  'a',\n",
       "  'sex',\n",
       "  'goddess',\n",
       "  'and',\n",
       "  'takes',\n",
       "  'on',\n",
       "  'a',\n",
       "  'role',\n",
       "  'of',\n",
       "  'real',\n",
       "  'depth',\n",
       "  'and',\n",
       "  'contradictions',\n",
       "  '.',\n",
       "  'finally',\n",
       "  ',',\n",
       "  'glenn',\n",
       "  'anders',\n",
       "  'strange',\n",
       "  'and',\n",
       "  'bizarre',\n",
       "  'portrayal',\n",
       "  'or',\n",
       "  'elsa',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'husbands',\n",
       "  \"'\",\n",
       "  'law',\n",
       "  'partner',\n",
       "  'is',\n",
       "  'nothing',\n",
       "  'short',\n",
       "  'of',\n",
       "  'classic',\n",
       "  '!'],\n",
       " 'ids': [100,\n",
       "  12,\n",
       "  7342,\n",
       "  5,\n",
       "  625,\n",
       "  12,\n",
       "  7079,\n",
       "  4,\n",
       "  2,\n",
       "  767,\n",
       "  5,\n",
       "  5863,\n",
       "  17,\n",
       "  35,\n",
       "  7,\n",
       "  2,\n",
       "  205,\n",
       "  114,\n",
       "  100,\n",
       "  40,\n",
       "  2123,\n",
       "  107,\n",
       "  3396,\n",
       "  43,\n",
       "  3393,\n",
       "  15072,\n",
       "  20,\n",
       "  258,\n",
       "  3734,\n",
       "  3415,\n",
       "  3,\n",
       "  475,\n",
       "  4,\n",
       "  6163,\n",
       "  5,\n",
       "  9175,\n",
       "  56,\n",
       "  400,\n",
       "  1131,\n",
       "  350,\n",
       "  4475,\n",
       "  4,\n",
       "  14,\n",
       "  23,\n",
       "  1375,\n",
       "  3863,\n",
       "  18,\n",
       "  6,\n",
       "  12608,\n",
       "  852,\n",
       "  23,\n",
       "  3,\n",
       "  2,\n",
       "  606,\n",
       "  7,\n",
       "  14,\n",
       "  23,\n",
       "  10,\n",
       "  1121,\n",
       "  19,\n",
       "  2123,\n",
       "  9,\n",
       "  7363,\n",
       "  9030,\n",
       "  7,\n",
       "  1031,\n",
       "  2460,\n",
       "  4,\n",
       "  1599,\n",
       "  1996,\n",
       "  4,\n",
       "  217,\n",
       "  7583,\n",
       "  5,\n",
       "  2914,\n",
       "  1473,\n",
       "  3,\n",
       "  2,\n",
       "  362,\n",
       "  7,\n",
       "  14835,\n",
       "  867,\n",
       "  232,\n",
       "  10,\n",
       "  6,\n",
       "  11870,\n",
       "  8,\n",
       "  2,\n",
       "  1039,\n",
       "  217,\n",
       "  657,\n",
       "  326,\n",
       "  12,\n",
       "  1190,\n",
       "  7,\n",
       "  459,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  1289,\n",
       "  1766,\n",
       "  111,\n",
       "  5,\n",
       "  2,\n",
       "  873,\n",
       "  12,\n",
       "  10531,\n",
       "  58,\n",
       "  70,\n",
       "  34,\n",
       "  1166,\n",
       "  18,\n",
       "  2,\n",
       "  2967,\n",
       "  4,\n",
       "  12,\n",
       "  117,\n",
       "  751,\n",
       "  4,\n",
       "  8,\n",
       "  4225,\n",
       "  3423,\n",
       "  9,\n",
       "  16,\n",
       "  10531,\n",
       "  3,\n",
       "  462,\n",
       "  4,\n",
       "  11,\n",
       "  10,\n",
       "  2123,\n",
       "  9,\n",
       "  2754,\n",
       "  19,\n",
       "  1755,\n",
       "  6621,\n",
       "  15,\n",
       "  4567,\n",
       "  14,\n",
       "  23,\n",
       "  12,\n",
       "  99,\n",
       "  6186,\n",
       "  3,\n",
       "  2,\n",
       "  119,\n",
       "  7,\n",
       "  14,\n",
       "  71,\n",
       "  10,\n",
       "  394,\n",
       "  424,\n",
       "  493,\n",
       "  6,\n",
       "  513,\n",
       "  4770,\n",
       "  9378,\n",
       "  7,\n",
       "  23,\n",
       "  3320,\n",
       "  3,\n",
       "  196,\n",
       "  4,\n",
       "  463,\n",
       "  14,\n",
       "  2926,\n",
       "  4,\n",
       "  2,\n",
       "  71,\n",
       "  2501,\n",
       "  19,\n",
       "  389,\n",
       "  358,\n",
       "  40,\n",
       "  2123,\n",
       "  4,\n",
       "  7141,\n",
       "  5,\n",
       "  267,\n",
       "  3441,\n",
       "  12036,\n",
       "  25,\n",
       "  2255,\n",
       "  24,\n",
       "  105,\n",
       "  14,\n",
       "  23,\n",
       "  6,\n",
       "  1800,\n",
       "  8,\n",
       "  112,\n",
       "  3,\n",
       "  4779,\n",
       "  2123,\n",
       "  2627,\n",
       "  138,\n",
       "  29,\n",
       "  70,\n",
       "  2,\n",
       "  2427,\n",
       "  0,\n",
       "  4,\n",
       "  22,\n",
       "  2,\n",
       "  3195,\n",
       "  8532,\n",
       "  18,\n",
       "  2,\n",
       "  1181,\n",
       "  22,\n",
       "  1671,\n",
       "  7309,\n",
       "  3,\n",
       "  5437,\n",
       "  7141,\n",
       "  4,\n",
       "  42,\n",
       "  17,\n",
       "  943,\n",
       "  8,\n",
       "  2123,\n",
       "  37,\n",
       "  2,\n",
       "  68,\n",
       "  4,\n",
       "  1952,\n",
       "  19,\n",
       "  47,\n",
       "  634,\n",
       "  546,\n",
       "  18,\n",
       "  6,\n",
       "  412,\n",
       "  10299,\n",
       "  5,\n",
       "  303,\n",
       "  28,\n",
       "  6,\n",
       "  215,\n",
       "  7,\n",
       "  157,\n",
       "  1163,\n",
       "  5,\n",
       "  14971,\n",
       "  3,\n",
       "  409,\n",
       "  4,\n",
       "  3441,\n",
       "  12036,\n",
       "  683,\n",
       "  5,\n",
       "  1088,\n",
       "  1116,\n",
       "  48,\n",
       "  7817,\n",
       "  9,\n",
       "  16,\n",
       "  5112,\n",
       "  9,\n",
       "  1278,\n",
       "  1909,\n",
       "  10,\n",
       "  167,\n",
       "  363,\n",
       "  7,\n",
       "  348,\n",
       "  36]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "678d0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.with_format(type='torch', columns=['ids', 'label'])\n",
    "valid_data = valid_data.with_format(type='torch', columns=['ids', 'label'])\n",
    "test_data = test_data.with_format(type='torch', columns=['ids', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a00726",
   "metadata": {},
   "source": [
    "Same thing as `set_format`, but not in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be56bf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'ids': tensor([  100,    12,  7342,     5,   625,    12,  7079,     4,     2,   767,\n",
       "             5,  5863,    17,    35,     7,     2,   205,   114,   100,    40,\n",
       "          2123,   107,  3396,    43,  3393, 15072,    20,   258,  3734,  3415,\n",
       "             3,   475,     4,  6163,     5,  9175,    56,   400,  1131,   350,\n",
       "          4475,     4,    14,    23,  1375,  3863,    18,     6, 12608,   852,\n",
       "            23,     3,     2,   606,     7,    14,    23,    10,  1121,    19,\n",
       "          2123,     9,  7363,  9030,     7,  1031,  2460,     4,  1599,  1996,\n",
       "             4,   217,  7583,     5,  2914,  1473,     3,     2,   362,     7,\n",
       "         14835,   867,   232,    10,     6, 11870,     8,     2,  1039,   217,\n",
       "           657,   326,    12,  1190,     7,   459,     4,     5,     2,  1289,\n",
       "          1766,   111,     5,     2,   873,    12, 10531,    58,    70,    34,\n",
       "          1166,    18,     2,  2967,     4,    12,   117,   751,     4,     8,\n",
       "          4225,  3423,     9,    16, 10531,     3,   462,     4,    11,    10,\n",
       "          2123,     9,  2754,    19,  1755,  6621,    15,  4567,    14,    23,\n",
       "            12,    99,  6186,     3,     2,   119,     7,    14,    71,    10,\n",
       "           394,   424,   493,     6,   513,  4770,  9378,     7,    23,  3320,\n",
       "             3,   196,     4,   463,    14,  2926,     4,     2,    71,  2501,\n",
       "            19,   389,   358,    40,  2123,     4,  7141,     5,   267,  3441,\n",
       "         12036,    25,  2255,    24,   105,    14,    23,     6,  1800,     8,\n",
       "           112,     3,  4779,  2123,  2627,   138,    29,    70,     2,  2427,\n",
       "             0,     4,    22,     2,  3195,  8532,    18,     2,  1181,    22,\n",
       "          1671,  7309,     3,  5437,  7141,     4,    42,    17,   943,     8,\n",
       "          2123,    37,     2,    68,     4,  1952,    19,    47,   634,   546,\n",
       "            18,     6,   412, 10299,     5,   303,    28,     6,   215,     7,\n",
       "           157,  1163,     5, 14971,     3,   409,     4,  3441, 12036,   683,\n",
       "             5,  1088,  1116,    48,  7817,     9,    16,  5112,     9,  1278,\n",
       "          1909,    10,   167,   363,     7,   348,    36])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba2ac8",
   "metadata": {},
   "source": [
    "Use `output_all_columns=True` to keep non-converted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "081f04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBoW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text = [batch size, seq len]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        pooled = embedded.mean(dim=1)\n",
    "        # pooled = [batch size, embedding dim]\n",
    "        prediction = self.fc(pooled)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97897898",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "output_dim = len(train_data.unique('label'))\n",
    "\n",
    "model = NBoW(vocab_size, embedding_dim, output_dim, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "866e0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.FastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ead7be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_vector = vectors.get_vecs_by_tokens('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a64ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ecc5d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5945e-01, -1.8259e-01,  3.3443e-02,  1.8813e-01, -6.7903e-02,\n",
       "        -1.3663e-01, -2.5559e-01,  1.1000e-01,  1.7275e-01,  5.1971e-02,\n",
       "        -2.3302e-02,  3.8866e-02, -2.4515e-01, -2.1588e-01,  3.5925e-01,\n",
       "        -8.2526e-02,  1.2176e-01, -2.6775e-01,  1.0072e-01, -1.3639e-01,\n",
       "        -9.2658e-02,  5.1837e-01,  1.7736e-01,  9.4878e-02, -1.8461e-01,\n",
       "        -4.2829e-02,  1.4114e-02,  1.6811e-01, -1.8565e-01,  3.4976e-02,\n",
       "        -1.0293e-01,  1.7954e-01, -5.2766e-02,  7.2047e-02, -4.2704e-01,\n",
       "        -1.1616e-01, -9.4875e-03,  1.4199e-01, -2.2782e-01, -1.7292e-02,\n",
       "         8.2802e-02, -4.4512e-01, -7.5935e-02, -1.4392e-01, -8.2461e-02,\n",
       "         2.0123e-01, -9.5344e-02, -1.1042e-01, -4.6817e-01,  2.0362e-01,\n",
       "        -1.7140e-01, -4.9850e-01,  2.8963e-01, -1.0305e-01,  2.0393e-01,\n",
       "         5.2971e-01, -2.5396e-01, -5.1891e-01,  2.9941e-01,  1.7933e-01,\n",
       "         3.0683e-01,  2.5828e-01, -1.8168e-01, -1.0225e-01, -1.1435e-01,\n",
       "        -1.6304e-01, -1.2424e-01,  3.2814e-01, -2.3099e-01,  1.7912e-01,\n",
       "         9.9206e-02,  1.8595e-01,  2.7996e-01,  1.8323e-01, -1.7397e-01,\n",
       "         2.6633e-01, -1.8151e-02,  2.8386e-01,  1.7328e-01,  2.9131e-01,\n",
       "         8.2289e-02,  1.8560e-01, -1.5544e-01,  2.3311e-01,  3.6578e-01,\n",
       "        -3.0802e-01, -1.5908e-01,  4.0382e-01,  1.5332e-01, -1.1630e-01,\n",
       "         1.3978e-01,  6.4237e-02,  2.2087e-01,  8.2723e-02,  1.2785e-01,\n",
       "        -6.6854e-02, -2.3016e-02, -1.9224e-01, -5.4482e-02,  3.7509e-01,\n",
       "         5.1194e-01, -2.3650e-01, -7.1224e-02,  8.1112e-02, -3.2017e-01,\n",
       "         5.0264e-02, -3.3223e-01,  2.2167e-02,  9.9936e-02, -2.7215e-01,\n",
       "        -7.2833e-02, -3.6598e-01,  1.7541e-01, -3.1303e-01, -2.3134e-01,\n",
       "        -1.5491e-01,  3.2102e-01,  1.2347e-01,  7.3616e-02,  2.0575e-01,\n",
       "         6.1732e-01,  7.1909e-02, -3.6930e-01,  4.7641e-01,  1.7456e-01,\n",
       "         3.2928e-01,  2.8792e-01, -7.6989e-02,  2.7030e-01,  6.9828e-01,\n",
       "         4.6247e-01,  4.1444e-01, -5.3405e-01,  4.4302e-01,  1.1631e-01,\n",
       "        -2.3425e-01, -1.5030e-01, -6.8092e-02,  3.3537e-01,  2.8618e-01,\n",
       "        -3.9781e-02,  2.3245e-01,  3.6262e-01, -1.7151e-01, -3.5204e-01,\n",
       "         1.9951e-01,  1.1345e-01, -4.5134e-01, -3.9699e-03, -2.0620e-01,\n",
       "        -4.9251e-02,  1.0825e-01,  1.2571e-01, -2.8134e-01,  1.0355e-01,\n",
       "         7.3498e-02, -2.6716e-01, -1.0001e-01, -2.2600e-01,  3.0784e-01,\n",
       "         2.5934e-01, -1.8112e-03, -2.0522e-01, -2.5115e-01, -1.5368e-01,\n",
       "         5.6060e-02, -6.4802e-02,  9.2786e-03,  2.6150e-01, -9.3972e-02,\n",
       "        -3.1032e-01, -2.6632e-01, -1.9598e-01, -4.5088e-02, -2.7611e-02,\n",
       "        -7.7027e-02,  1.5070e-01,  1.7185e-01, -8.5416e-02, -1.4448e-01,\n",
       "        -2.4800e-03, -3.2881e-01, -1.6913e-01, -1.2778e-01, -2.3352e-01,\n",
       "         1.5178e-01, -6.9358e-01, -3.8922e-01,  3.7190e-01,  2.6020e-01,\n",
       "        -1.0232e-01, -6.0247e-01, -5.4548e-02,  6.6532e-01, -7.3208e-02,\n",
       "        -2.3644e-01, -2.5550e-01,  1.9755e-02, -4.8908e-01, -7.3706e-02,\n",
       "         3.0545e-01,  2.4459e-01,  2.0426e-01, -3.0128e-01,  6.0666e-02,\n",
       "         1.8107e-02, -9.6162e-02, -2.0348e-02, -1.9801e-04,  2.9652e-02,\n",
       "         5.0787e-01, -2.0225e-01, -6.1565e-02, -2.7330e-01, -3.7789e-01,\n",
       "        -2.4373e-01,  9.4902e-02, -3.7236e-01, -8.5854e-02,  2.4096e-01,\n",
       "        -1.7998e-01,  7.3902e-02, -7.8217e-04, -1.8559e-01, -2.6445e-01,\n",
       "        -2.3306e-02, -1.8644e-01, -1.0638e-01,  8.9330e-02,  4.1039e-01,\n",
       "         1.0452e-02, -9.8721e-03, -1.8335e-01, -2.8524e-01, -1.4771e-01,\n",
       "        -1.9499e-01, -1.0175e-01,  1.2292e-01,  8.3651e-02, -2.1228e-01,\n",
       "         3.4773e-02,  6.1831e-02,  2.9237e-01,  1.4371e-01, -9.2354e-02,\n",
       "         8.1267e-03,  2.7648e-01,  2.1753e-01,  2.6609e-01, -3.6083e-01,\n",
       "         2.8347e-01, -2.9295e-01, -2.6441e-01,  2.1056e-01,  3.2068e-01,\n",
       "        -1.6156e-01,  1.5298e-01, -1.5577e-01,  2.2035e-01, -1.1888e-01,\n",
       "         1.3766e-01, -9.9048e-02,  4.1584e-01, -3.6029e-02, -6.2504e-02,\n",
       "         3.3177e-01, -1.3997e-01,  8.7884e-02, -2.1428e-01, -6.2643e-01,\n",
       "        -3.1293e-01, -3.4895e-01,  5.2294e-01, -1.2635e-01, -1.9371e-01,\n",
       "        -2.0631e-01,  5.3758e-01, -1.1522e-01, -2.3659e-01,  2.0457e-01,\n",
       "         1.9534e-01,  3.3260e-01, -2.2254e-01,  8.1346e-02, -7.2798e-02,\n",
       "        -8.6357e-04, -1.0199e-01,  3.1601e-01,  2.0040e-01,  1.9014e-01,\n",
       "        -9.6766e-02,  2.5155e-01, -2.0484e-01, -4.5859e-01,  1.1687e-01,\n",
       "        -3.3574e-01, -3.3371e-01,  8.6787e-02,  2.4920e-01,  6.5367e-02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8540b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d31228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26232, 300])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a6f4173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1258, -1.1524, -0.2506,  ...,  0.8200, -0.6332,  1.2948],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1483,  2.4187,  1.3279,  ..., -1.0328,  1.1305, -0.5703],\n",
       "        ...,\n",
       "        [-0.2703, -0.1223,  0.1723,  ...,  1.0298, -0.4671,  1.5620],\n",
       "        [-0.4065, -1.0677,  0.3959,  ..., -0.0393, -1.2843, -1.2270],\n",
       "        [-0.3655, -0.0831,  0.9841,  ...,  1.5278, -0.3701,  0.7942]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c1cbd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0653, -0.0930, -0.0176,  ...,  0.1664, -0.1308,  0.0354],\n",
       "        ...,\n",
       "        [-0.3563,  0.1529, -0.6328,  ...,  0.2229,  0.8131, -0.2988],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1161, -0.0390,  0.1120,  ...,  0.0925, -0.1058,  0.5641]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ea34c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data = pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1332d9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0653, -0.0930, -0.0176,  ...,  0.1664, -0.1308,  0.0354],\n",
       "        ...,\n",
       "        [-0.3563,  0.1529, -0.6328,  ...,  0.2229,  0.8131, -0.2988],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1161, -0.0390,  0.1120,  ...,  0.0925, -0.1058,  0.5641]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fcb95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8829cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ed273e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cdaf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c721ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch, pad_index):\n",
    "    batch_ids = [i['ids'] for i in batch]\n",
    "    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n",
    "    batch_labels = [i['label'] for i in batch]\n",
    "    batch_labels = torch.stack(batch_labels)\n",
    "    batch = {'ids': batch_ids,\n",
    "             'label': batch_labels}\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adf5afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "collate = functools.partial(collate, pad_index=pad_index)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, \n",
    "                                               batch_size=batch_size, \n",
    "                                               collate_fn=collate, \n",
    "                                               shuffle=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "729aa9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        tokens = batch['ids'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        prediction = model(tokens)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0a80c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            tokens = batch['ids'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            prediction = model(tokens)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "703aa1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size = prediction.shape[0]\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31343f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.565\n",
      "valid_loss: 0.686, valid_acc: 0.635\n",
      "epoch: 2\n",
      "train_loss: 0.678, train_acc: 0.667\n",
      "valid_loss: 0.671, valid_acc: 0.698\n",
      "epoch: 3\n",
      "train_loss: 0.654, train_acc: 0.721\n",
      "valid_loss: 0.644, valid_acc: 0.728\n",
      "epoch: 4\n",
      "train_loss: 0.619, train_acc: 0.753\n",
      "valid_loss: 0.611, valid_acc: 0.754\n",
      "epoch: 5\n",
      "train_loss: 0.579, train_acc: 0.784\n",
      "valid_loss: 0.577, valid_acc: 0.778\n",
      "epoch: 6\n",
      "train_loss: 0.538, train_acc: 0.810\n",
      "valid_loss: 0.541, valid_acc: 0.802\n",
      "epoch: 7\n",
      "train_loss: 0.497, train_acc: 0.835\n",
      "valid_loss: 0.509, valid_acc: 0.822\n",
      "epoch: 8\n",
      "train_loss: 0.459, train_acc: 0.856\n",
      "valid_loss: 0.481, valid_acc: 0.837\n",
      "epoch: 9\n",
      "train_loss: 0.425, train_acc: 0.871\n",
      "valid_loss: 0.455, valid_acc: 0.848\n",
      "epoch: 10\n",
      "train_loss: 0.398, train_acc: 0.880\n",
      "valid_loss: 0.434, valid_acc: 0.856\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(valid_dataloader, model, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'nbow.pt')\n",
    "    \n",
    "    print(f'epoch: {epoch+1}')\n",
    "    print(f'train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}')\n",
    "    print(f'valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cac26e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.429, test_acc: 0.848\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('nbow.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n",
    "\n",
    "print(f'test_loss: {test_loss:.3f}, test_acc: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b22e040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, vocab, device):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = [vocab[t] for t in tokens]\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cfa14eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is terrible!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1da60d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is great!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bee6190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.8084420561790466)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is not terrible, it's great!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3d55c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.8084420561790466)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is not great, it's terrible!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
