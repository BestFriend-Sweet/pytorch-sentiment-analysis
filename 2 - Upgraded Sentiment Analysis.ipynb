{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Simple Sentiment Analysis\n",
    "\n",
    "In this series we'll be building a *machine learning* model to detect sentiment (i.e. detect if a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews using the IMDb dataset.\n",
    "\n",
    "In this first notebook, we'll start very simple to understand the general concepts, whilst further notebooks will build on this knowledge.\n",
    "\n",
    "We'll be using a **recurrent neural network** (RNN) which reads a sequence of words, and for each word (sometimes called a _step_) will output a _hidden state_. We then use the hidden state for subsequent word in the sentence, until the final word has been fed into the RNN. This final hidden state will then be used to predict the sentiment of the sentence.\n",
    "\n",
    "![](https://i.imgur.com/VedY9iG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(sequential=False, tensor_type=torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 25000\n"
     ]
    }
   ],
   "source": [
    "print('len(train)', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7f63ed58c780>, 'label': <torchtext.data.field.LabelField object at 0x7f63ed58c710>}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vars(train[0]) {'text': ['elvira', 'mistress', 'of', 'the', 'dark', 'is', 'one', 'of', 'my', 'fav', 'movies,', 'it', 'has', 'every', 'thing', 'you', 'would', 'want', 'in', 'a', 'film,', 'like', 'great', 'one', 'liners,', 'sexy', 'star', 'and', 'a', 'Outrageous', 'story!', 'if', 'you', 'have', 'not', 'seen', 'it,', 'you', 'are', 'missing', 'out', 'on', 'one', 'of', 'the', 'greatest', 'films', 'made.', 'i', \"can't\", 'wait', 'till', 'her', 'new', 'movie', 'comes', 'out!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 17500\n",
      "len(valid) 7500\n",
      "len(test) 25000\n"
     ]
    }
   ],
   "source": [
    "print('len(train)', len(train))\n",
    "print('len(valid)', len(valid))\n",
    "print('len(test)', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(train, max_size=25000)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 25002\n",
      "len(LABEL.vocab) 2\n"
     ]
    }
   ],
   "source": [
    "# print vocab information\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('len(LABEL.vocab)', len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 200172), ('a', 108127), ('and', 106433), ('of', 99579), ('to', 92133), ('is', 71636), ('in', 60019), ('I', 46381), ('that', 44914), ('this', 39894), ('it', 37997), ('/><br', 35251), ('was', 32575), ('as', 29712), ('with', 28885), ('for', 28549), ('The', 23679), ('but', 23518), ('movie', 21506), ('on', 21341), ('are', 19802), ('his', 19204), ('film', 18973), ('have', 18926), ('not', 18269), ('be', 17899), ('you', 17610), ('he', 15175), ('by', 14940), ('at', 14900), ('one', 14343), ('an', 14273), ('from', 13439), ('who', 13170), ('like', 12641), ('all', 12530), ('they', 12342), ('so', 11469), ('has', 11435), ('about', 11396), ('just', 11388), ('or', 11272), ('her', 11025), ('out', 10060), ('some', 9858), ('very', 9094), ('more', 9025), ('This', 8532), ('would', 8311), ('what', 8172), ('when', 8127), ('good', 8086), ('only', 7845), ('if', 7751), ('their', 7724), ('had', 7645), ('It', 7602), ('really', 7555), (\"it's\", 7503), ('which', 7421), ('up', 7391), ('even', 7316), ('can', 7277), ('were', 7274), ('no', 7116), ('see', 7113), ('my', 7103), ('she', 6965), ('than', 6771), ('-', 6550), ('been', 6370), ('there', 6313), ('into', 6228), ('get', 6122), ('will', 5994), ('story', 5957), ('much', 5933), ('because', 5798), ('other', 5558), ('most', 5513), ('time', 5438), ('we', 5436), ('me', 5335), ('how', 5275), ('could', 5243), ('make', 5222), ('do', 5190), ('also', 5137), ('its', 5109), ('first', 5104), ('people', 5079), ('great', 5044), ('any', 4996), ('/>The', 4951), (\"don't\", 4895), ('made', 4841), ('think', 4675), ('bad', 4575), ('him', 4452), ('being', 4330)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f6393c51400>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, valid, test), \n",
    "    batch_size=64, \n",
    "    sort_key=lambda x: len(x.text), \n",
    "    sort_within_batch=True, \n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "Updates to model:\n",
    "- Use a special RNN architecture called _LSTM_\n",
    "- Increase the number of _layers_ of the RNN/LSTM\n",
    "- The RNN/LSTM is _bi-directional_\n",
    "- Added regularization in the form of _dropout_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(x.shape)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        #print(embedded.shape)\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        #print(output.shape)\n",
    "        #print(hidden.shape)\n",
    "        #print(output[-1,:,:])\n",
    "        #print(output[-1,:,:].shape)\n",
    "        #print(hidden.shape)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(len(TEXT.vocab), 128, 256, 1, 2, True, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(10, 32, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(F.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float or division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/.conda/envs/pytorch04/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Acc: 53.22%, Val. Acc: 58.03%\n",
      "Epoch: 2, Train Acc: 64.11%, Val. Acc: 70.57%\n",
      "Epoch: 3, Train Acc: 72.43%, Val. Acc: 77.12%\n",
      "Epoch: 4, Train Acc: 79.70%, Val. Acc: 81.24%\n",
      "Epoch: 5, Train Acc: 83.71%, Val. Acc: 81.09%\n",
      "Epoch: 6, Train Acc: 85.21%, Val. Acc: 84.86%\n",
      "Epoch: 7, Train Acc: 87.77%, Val. Acc: 85.52%\n",
      "Epoch: 8, Train Acc: 89.01%, Val. Acc: 86.71%\n",
      "Epoch: 9, Train Acc: 89.95%, Val. Acc: 88.22%\n",
      "Epoch: 10, Train Acc: 91.08%, Val. Acc: 88.34%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, optimizer, criterion)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, Train Acc: {train_acc*100:.2f}%, Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/.conda/envs/pytorch04/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 88.25%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iter, optimizer, criterion)\n",
    "\n",
    "print(f'Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005002327263355255"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = F.sigmoid(model(tensor))\n",
    "    return prediction.item()\n",
    "\n",
    "predict_sentiment(\"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970943927764893"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"This film is amazing!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
