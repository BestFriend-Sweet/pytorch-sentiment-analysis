{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655f49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d705d34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faeccf1e990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1478c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = datasets.load_dataset('imdb', split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df32c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf606b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(example, tokenizer, max_length):\n",
    "    tokens = tokenizer(example['text'])[:max_length]\n",
    "    length = len(tokens)\n",
    "    return {'tokens': tokens, 'length': length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4791b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-98e263656f586667.arrow\n",
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-08f9ff60341e8990.arrow\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "train_data = train_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})\n",
    "test_data = test_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer, 'max_length': max_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b59e038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-28b136fb2a4d67fd.arrow and /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-8fa05fb343b1e79a.arrow\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "\n",
    "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
    "train_data = train_valid_data['train']\n",
    "valid_data = train_valid_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9394aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 5\n",
    "special_tokens = ['<unk>', '<pad>']\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(train_data['tokens'],\n",
    "                                                  min_freq=min_freq,\n",
    "                                                  specials=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9424ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = vocab['<unk>']\n",
    "pad_index = vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccd722fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d146c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_data(example, vocab):\n",
    "    ids = [vocab[token] for token in example['tokens']]\n",
    "    return {'ids': ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1eb4b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-631f583ffb0d9c68.arrow\n",
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-6f5a6c52dcbaf2d0.arrow\n",
      "Loading cached processed dataset at /home/ben/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-c455c5d5c41c2779.arrow\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\n",
    "valid_data = valid_data.map(numericalize_data, fn_kwargs={'vocab': vocab})\n",
    "test_data = test_data.map(numericalize_data, fn_kwargs={'vocab': vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a751c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.with_format(type='torch', columns=['ids', 'label', 'length'])\n",
    "valid_data = valid_data.with_format(type='torch', columns=['ids', 'label', 'length'])\n",
    "test_data = test_data.with_format(type='torch', columns=['ids', 'label', 'length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473541be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'length': tensor(256),\n",
       " 'ids': tensor([   98,    13,  6329,     6,   559,    13,  6491,     4,     2,   763,\n",
       "             6,  6300,    17,    34,     7,     2,   195,   116,    98,    40,\n",
       "          2302,   102,  3497,    44,  3318, 15422,    21,   261,  3609,  3433,\n",
       "             3,   474,     4,  6093,     6, 10888,    54,   396,  1198,   338,\n",
       "          4479,     4,    14,    23,  1481,  3596,    19,     5, 13453,   850,\n",
       "            23,     3,     2,   639,     7,    14,    23,    10,  1073,    20,\n",
       "          2302,     9,  7180,  9372,     7,  1045,  2522,     4,  1706,  2115,\n",
       "             4,   212,  8127,     6,  3179,  1485,     3,     2,   386,     7,\n",
       "         13210,   860,   233,    10,     5, 12948,     8,     2,   984,   212,\n",
       "           628,   346,    13,  1228,     7,   462,     4,     6,     2,  1236,\n",
       "          1675,   114,     6,     2,   905,    13, 10802,    59,    71,    35,\n",
       "          1132,    19,     2,  3009,     4,    13,   117,   771,     4,     8,\n",
       "          3582,  3534,     9,    16, 10802,     3,   446,     4,    11,    10,\n",
       "          2302,     9,  3013,    20,  1810,  6389,    15,  4846,    14,    23,\n",
       "            13,   100,  6865,     3,     2,   113,     7,    14,    64,    10,\n",
       "           406,   443,   527,     5,   525,  4470, 10812,     7,    23,  3324,\n",
       "             3,   190,     4,   500,    14,  3049,     4,     2,    64,  2675,\n",
       "            20,   356,   389,    40,  2302,     4,  7843,     6,   262,  3111,\n",
       "         14039,    25,  2146,    24,   106,    14,    23,     5,  1777,     8,\n",
       "           108,     3,  4281,  2302,  2890,   137,    29,    71,     2,  2386,\n",
       "             0,     4,    22,     2,  3544,  7847,    19,     2,  1172,    22,\n",
       "          1813,  7915,     3,  6041,  7843,     4,    42,    17,   922,     8,\n",
       "          2302,    38,     2,    65,     4,  2100,    20,    50,   604,   556,\n",
       "            19,     5,   416, 11476,     6,   310,    27,     5,   221,     7,\n",
       "           158,  1248,     6, 16505,     3,   454,     4,  3111, 14039,   637,\n",
       "             6,  1079,  1074,    49,  8928,     9])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fdb0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
    "                 dropout_rate, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
    "                            dropout=dropout_rate, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, ids, length):\n",
    "        # ids = [batch size, seq len]\n",
    "        # length = [batch size]\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        # embedded = [batch size, seq len, embedding dim]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, length, batch_first=True, \n",
    "                                                            enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # output = [batch size, seq len, hidden dim * n directions]\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "            # hidden = [batch size, hidden dim * 2]\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "            # hidden = [batch size, hidden dim]\n",
    "        prediction = self.fc(hidden)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecf55277",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = len(train_data.unique('label'))\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.75\n",
    "\n",
    "model = LSTM(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n",
    "             pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dea876de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,073,702 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "396d9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.orthogonal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68a44088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(21543, 300, padding_idx=1)\n",
       "  (lstm): LSTM(300, 300, num_layers=2, batch_first=True, dropout=0.75, bidirectional=True)\n",
       "  (fc): Linear(in_features=600, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.75, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c52fa39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.FastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155d9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69175fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data = pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fccff0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1330efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2063a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20d0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c95cb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch, pad_index):\n",
    "    batch_ids = [i['ids'] for i in batch]\n",
    "    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n",
    "    batch_length = [i['length'] for i in batch]\n",
    "    batch_length = torch.stack(batch_length)\n",
    "    batch_label = [i['label'] for i in batch]\n",
    "    batch_label = torch.stack(batch_label)\n",
    "    batch = {'ids': batch_ids,\n",
    "             'length': batch_length,\n",
    "             'label': batch_label}\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d48adc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "collate = functools.partial(collate, pad_index=pad_index)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, \n",
    "                                               batch_size=batch_size, \n",
    "                                               collate_fn=collate, \n",
    "                                               shuffle=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47cedaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        ids = batch['ids'].to(device)\n",
    "        length = batch['length']\n",
    "        label = batch['label'].to(device)\n",
    "        prediction = model(ids, length)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbb4b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            ids = batch['ids'].to(device)\n",
    "            length = batch['length']\n",
    "            label = batch['label'].to(device)\n",
    "            prediction = model(ids, length)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cb9cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff17d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train_loss: 0.649, train_acc: 0.605\n",
      "valid_loss: 0.637, valid_acc: 0.682\n",
      "epoch: 2\n",
      "train_loss: 0.563, train_acc: 0.710\n",
      "valid_loss: 0.611, valid_acc: 0.642\n",
      "epoch: 3\n",
      "train_loss: 0.594, train_acc: 0.697\n",
      "valid_loss: 0.710, valid_acc: 0.688\n",
      "epoch: 4\n",
      "train_loss: 0.590, train_acc: 0.692\n",
      "valid_loss: 0.517, valid_acc: 0.750\n",
      "epoch: 5\n",
      "train_loss: 0.535, train_acc: 0.733\n",
      "valid_loss: 0.687, valid_acc: 0.507\n",
      "epoch: 6\n",
      "train_loss: 0.677, train_acc: 0.566\n",
      "valid_loss: 0.635, valid_acc: 0.679\n",
      "epoch: 7\n",
      "train_loss: 0.593, train_acc: 0.704\n",
      "valid_loss: 0.685, valid_acc: 0.545\n",
      "epoch: 8\n",
      "train_loss: 0.653, train_acc: 0.587\n",
      "valid_loss: 0.648, valid_acc: 0.630\n",
      "epoch: 9\n",
      "train_loss: 0.613, train_acc: 0.658\n",
      "valid_loss: 0.545, valid_acc: 0.737\n",
      "epoch: 10\n",
      "train_loss: 0.533, train_acc: 0.754\n",
      "valid_loss: 0.474, valid_acc: 0.796\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(valid_dataloader, model, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'lstm.pt')\n",
    "    \n",
    "    print(f'epoch: {epoch+1}')\n",
    "    print(f'train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}')\n",
    "    print(f'valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02e57fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.469, test_acc: 0.797\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lstm.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n",
    "\n",
    "print(f'test_loss: {test_loss:.3f}, test_acc: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2abd89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, vocab, device):\n",
    "    tokens = tokenizer(text)\n",
    "    ids = [vocab[t] for t in tokens]\n",
    "    length = torch.LongTensor([len(ids)])\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor, length).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79c09924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.8488112688064575)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is terrible!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d43c06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.7834495902061462)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is great!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "501e12e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.5829631090164185)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is not terrible, it's great!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a2f732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.6761167645454407)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This film is not great, it's terrible!\"\n",
    "\n",
    "predict_sentiment(text, model, tokenizer, vocab, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
